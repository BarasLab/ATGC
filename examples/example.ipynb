{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from figures.controls.samples.sim_data.sim_data_tools import *\n",
    "import pylab as plt\n",
    "import tensorflow as tf\n",
    "from model.Sample_MIL import InstanceModels, RaggedModels\n",
    "from model import DatasetsUtils\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[-1], True)\n",
    "tf.config.experimental.set_visible_devices(physical_devices[-1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Let's create some simulated mutation data where the positive class is defined by having mutations with a specific sequence 5' of the mutation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def generate_sample(mean_variants=[5, 10, 20, 30, 40, 50, 70, 100, 150, 200, 250, 300],\n",
    "                    control=True, positive_choices=None, negative_instances=False, fixed=['five_p']):\n",
    "    if negative_instances and len(positive_choices) <= 1:\n",
    "        raise ValueError\n",
    "    center = np.random.choice(mean_variants, 1)\n",
    "    total_count = int(np.random.normal(center, int(np.ceil(center * .2))))\n",
    "    if total_count < 1:\n",
    "        total_count *= -1\n",
    "    if total_count == 0:\n",
    "        total_count = np.random.choice([2, 3, 4, 5, 6], 1)\n",
    "    if control:\n",
    "        if negative_instances:\n",
    "            positive_count = int(np.ceil(np.random.random() * total_count))\n",
    "            control_count = total_count - positive_count\n",
    "        else:\n",
    "            control_count = total_count\n",
    "            positive_count = 0\n",
    "    else:\n",
    "        positive_counts = [int(np.ceil(np.random.random() / len(positive_choices) * total_count)) for i in positive_choices]\n",
    "        control_count = total_count - sum(positive_counts)\n",
    "\n",
    "    control_count = max(control_count, 0)\n",
    "    positive_variants = []\n",
    "    positive_instances = []\n",
    "\n",
    "    control_variants = [generate_variant() for i in range(control_count)]\n",
    "    if control:\n",
    "        while True:\n",
    "            y = False\n",
    "            for i in control_variants:\n",
    "                if check_variant(i, positive_choices, to_check=fixed):\n",
    "                    y = True\n",
    "                    break\n",
    "            if y:\n",
    "                control_variants = [generate_variant() for i in range(control_count)]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    if control:\n",
    "        if negative_instances:\n",
    "            positive_choice = int(np.random.choice(range(len(positive_choices)), 1))\n",
    "            for i in range(positive_count):\n",
    "                positive_variant = list(generate_variant())\n",
    "                if 'five_p' in fixed:\n",
    "                    positive_variant[0] = positive_choices[positive_choice][0]\n",
    "                if 'three_p' in fixed:\n",
    "                    positive_variant[1] = positive_choices[positive_choice][1]\n",
    "                if 'ref' in fixed:\n",
    "                    positive_variant[2] = positive_choices[positive_choice][2]\n",
    "                if 'alt' in fixed:\n",
    "                    positive_variant[3] = positive_choices[positive_choice][3]\n",
    "                positive_variants.append(positive_variant)\n",
    "                positive_instances.append(positive_choice + 1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        for index, i in enumerate(positive_choices):\n",
    "            for ii in range(positive_counts[index]):\n",
    "                positive_variant = list(generate_variant())\n",
    "                if 'five_p' in fixed:\n",
    "                    positive_variant[0] = i[0]\n",
    "                if 'three_p' in fixed:\n",
    "                    positive_variant[1] = i[1]\n",
    "                if 'ref' in fixed:\n",
    "                    positive_variant[2] = i[2]\n",
    "                if 'alt' in fixed:\n",
    "                    positive_variant[3] = i[3]\n",
    "                positive_variants.append(positive_variant)\n",
    "                positive_instances.append(index + 1)\n",
    "\n",
    "    return [control_variants + positive_variants, [0] * len(control_variants) + positive_instances]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will collect information about the individual mutations in a dictionary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "instances = {'sample_idx': [],\n",
    "                 'seq_5p': [],\n",
    "                 'seq_3p': [],\n",
    "                  'seq_ref': [],\n",
    "                  'seq_alt': [],\n",
    "                  'strand': [],\n",
    "                  'cds': [],\n",
    "                  'class': []}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#And we will also collect information about the samples the mutations belong to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "samples = {'classes': []}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Need to generate the motif which will define the positive class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "positive_choices = [generate_variant() for i in range(1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(1000):\n",
    "    if np.random.sample() < .5:\n",
    "        variants = generate_sample(positive_choices=positive_choices)\n",
    "        samples['classes'] = samples['classes'] + [0]\n",
    "    else:\n",
    "        variants = generate_sample(control=False, positive_choices=positive_choices)\n",
    "        samples['classes'] = samples['classes'] + [1]\n",
    "    instances['sample_idx'] = instances['sample_idx'] + [idx] * len(variants[0])\n",
    "    instances['seq_5p'] = instances['seq_5p'] + [i[0] for i in variants[0]]\n",
    "    instances['seq_3p'] = instances['seq_3p'] + [i[1] for i in variants[0]]\n",
    "    instances['seq_ref'] = instances['seq_ref'] + [i[2] for i in variants[0]]\n",
    "    instances['seq_alt'] = instances['seq_alt'] + [i[3] for i in variants[0]]\n",
    "    instances['strand'] = instances['strand'] + [i[6] for i in variants[0]]\n",
    "    instances['cds'] = instances['cds'] + [0 for i in variants[0]]\n",
    "    instances['class'] = instances['class'] + variants[1]\n",
    "\n",
    "for i in instances:\n",
    "    instances[i] = np.array(instances[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples['classes'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0, 1]), array([478, 522]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(samples['classes'], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "97261"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances['sample_idx'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We made 1000 samples with 478 being of the negative class and 522 the positive class.  These samples are composed of 97261 mutations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Let's look at the distribution of mutations per sample.  You can alter the distribution to mirror the data you expect."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Mutations per Sample')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGwCAYAAACD0J42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvNElEQVR4nO3df1TUdb7H8dcgMpA4g/iDkRsoxzVF81f+QNLdLLmhsq6a/bBLSeZmtWApZcm5YT+2wrpWpmta2UXbk2u3e9VN29xYLLgVoqLeysis/MFNB9przAgGInzvH3ua0yQp2CAf8Pk453uO8/l85jPv73z0zMvPfGfGZlmWJQAAAIMEtXYBAAAAP0ZAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwTnBrF3A+GhoadPToUXXu3Fk2m621ywEAAE1gWZZOnDih6OhoBQWdfY+kTQaUo0ePKiYmprXLAAAA56GsrEyXXnrpWce0yYDSuXNnSf84QYfD0crVAACApvB6vYqJifG9jp9Nmwwo37+t43A4CCgAALQxTbk8g4tkAQCAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABin2QGlsLBQkydPVnR0tGw2mzZt2nTGmNLSUv3mN7+R0+lUp06dNHLkSB05csTXX1NTo/T0dHXt2lXh4eGaPn26ysvLf9aJAACA9qPZAaW6ulpDhgzRihUrGu3/8ssvNXbsWPXv31/vvfeePvroI2VnZys0NNQ3Zv78+dq8ebPeeOMNFRQU6OjRo7ruuuvO/ywAAEC7YrMsyzrvO9ts2rhxo6ZOneprmzFjhjp27Kg//vGPjd7H4/Goe/fuWrduna6//npJ0meffab4+HgVFRVp9OjR53xcr9crp9Mpj8cjh8NxvuX/pN4L3zrnmEOLUwL+uAAAtGfNef0O6DUoDQ0Neuutt3TZZZcpOTlZPXr0UEJCgt/bQCUlJaqrq1NSUpKvrX///oqNjVVRUVGj89bW1srr9fodAACg/QpoQKmoqFBVVZUWL16sCRMm6J133tG0adN03XXXqaCgQJLkdrsVEhKiiIgIv/tGRUXJ7XY3Om9OTo6cTqfviImJCWTZAADAMAHfQZGkKVOmaP78+Ro6dKgWLlyoX//611q1atV5z5uVlSWPx+M7ysrKAlUyAAAwUHAgJ+vWrZuCg4M1YMAAv/b4+Hi9//77kiSXy6VTp06psrLSbxelvLxcLper0XntdrvsdnsgSwUAAAYL6A5KSEiIRo4cqf379/u1f/755+rVq5ckafjw4erYsaPy8/N9/fv379eRI0eUmJgYyHIAAEAb1ewdlKqqKn3xxRe+2wcPHtTevXsVGRmp2NhYLViwQDfddJN+9atf6eqrr9bWrVu1efNmvffee5Ikp9Op2bNnKzMzU5GRkXI4HJo7d64SExOb9AkeAADQ/jU7oOzatUtXX32173ZmZqYkKS0tTWvWrNG0adO0atUq5eTk6J577lG/fv30X//1Xxo7dqzvPs8995yCgoI0ffp01dbWKjk5WS+88EIATgcAALQHP+t7UFoL34MCAEDb02rfgwIAABAIBBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDjNDiiFhYWaPHmyoqOjZbPZtGnTpp8ce9ddd8lms2np0qV+7cePH1dqaqocDociIiI0e/ZsVVVVNbcUAADQTjU7oFRXV2vIkCFasWLFWcdt3LhR27dvV3R09Bl9qamp2rdvn/Ly8rRlyxYVFhZqzpw5zS0FAAC0U8HNvcPEiRM1ceLEs475+uuvNXfuXP31r39VSkqKX19paam2bt2qnTt3asSIEZKk5cuXa9KkSVqyZEmjgQYAAFxcAn4NSkNDg2699VYtWLBAAwcOPKO/qKhIERERvnAiSUlJSQoKClJxcXGjc9bW1srr9fodAACg/Qp4QHnqqacUHByse+65p9F+t9utHj16+LUFBwcrMjJSbre70fvk5OTI6XT6jpiYmECXDQAADBLQgFJSUqLnn39ea9askc1mC9i8WVlZ8ng8vqOsrCxgcwMAAPMENKD893//tyoqKhQbG6vg4GAFBwfr8OHDuu+++9S7d29JksvlUkVFhd/9Tp8+rePHj8vlcjU6r91ul8Ph8DsAAED71eyLZM/m1ltvVVJSkl9bcnKybr31Vs2aNUuSlJiYqMrKSpWUlGj48OGSpG3btqmhoUEJCQmBLAcAALRRzQ4oVVVV+uKLL3y3Dx48qL179yoyMlKxsbHq2rWr3/iOHTvK5XKpX79+kqT4+HhNmDBBd9xxh1atWqW6ujplZGRoxowZfIIHAABIOo+3eHbt2qVhw4Zp2LBhkqTMzEwNGzZMixYtavIcr732mvr376/x48dr0qRJGjt2rF566aXmlgIAANqpZu+gjBs3TpZlNXn8oUOHzmiLjIzUunXrmvvQAADgIsFv8QAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4zQ7oBQWFmry5MmKjo6WzWbTpk2bfH11dXV68MEHNWjQIHXq1EnR0dGaOXOmjh496jfH8ePHlZqaKofDoYiICM2ePVtVVVU/+2QAAED70OyAUl1drSFDhmjFihVn9J08eVK7d+9Wdna2du/erQ0bNmj//v36zW9+4zcuNTVV+/btU15enrZs2aLCwkLNmTPn/M8CAAC0KzbLsqzzvrPNpo0bN2rq1Kk/OWbnzp0aNWqUDh8+rNjYWJWWlmrAgAHauXOnRowYIUnaunWrJk2apP/93/9VdHT0GXPU1taqtrbWd9vr9SomJkYej0cOh+N8y/9JvRe+dc4xhxanBPxxAQBoz7xer5xOZ5Nev1v8GhSPxyObzaaIiAhJUlFRkSIiInzhRJKSkpIUFBSk4uLiRufIycmR0+n0HTExMS1dNgAAaEUtGlBqamr04IMP6uabb/YlJbfbrR49eviNCw4OVmRkpNxud6PzZGVlyePx+I6ysrKWLBsAALSy4JaauK6uTjfeeKMsy9LKlSt/1lx2u112uz1AlQEAANO1SED5PpwcPnxY27Zt83ufyeVyqaKiwm/86dOndfz4cblcrpYoBwAAtDEBf4vn+3By4MAB/e1vf1PXrl39+hMTE1VZWamSkhJf27Zt29TQ0KCEhIRAlwMAANqgZu+gVFVV6YsvvvDdPnjwoPbu3avIyEj17NlT119/vXbv3q0tW7aovr7ed11JZGSkQkJCFB8frwkTJuiOO+7QqlWrVFdXp4yMDM2YMaPRT/AAAICLT7MDyq5du3T11Vf7bmdmZkqS0tLS9Mgjj+jNN9+UJA0dOtTvfu+++67GjRsnSXrttdeUkZGh8ePHKygoSNOnT9eyZcvO8xQAAEB70+yAMm7cOJ3tq1Oa8rUqkZGRWrduXXMfGgAAXCT4LR4AAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDjNDiiFhYWaPHmyoqOjZbPZtGnTJr9+y7K0aNEi9ezZU2FhYUpKStKBAwf8xhw/flypqalyOByKiIjQ7NmzVVVV9bNOBAAAtB/NDijV1dUaMmSIVqxY0Wj/008/rWXLlmnVqlUqLi5Wp06dlJycrJqaGt+Y1NRU7du3T3l5edqyZYsKCws1Z86c8z8LAADQrgQ39w4TJ07UxIkTG+2zLEtLly7VQw89pClTpkiSXn31VUVFRWnTpk2aMWOGSktLtXXrVu3cuVMjRoyQJC1fvlyTJk3SkiVLFB0d/TNOBwAAtAcBvQbl4MGDcrvdSkpK8rU5nU4lJCSoqKhIklRUVKSIiAhfOJGkpKQkBQUFqbi4uNF5a2tr5fV6/Q4AANB+BTSguN1uSVJUVJRfe1RUlK/P7XarR48efv3BwcGKjIz0jfmxnJwcOZ1O3xETExPIsgEAgGHaxKd4srKy5PF4fEdZWVlrlwQAAFpQQAOKy+WSJJWXl/u1l5eX+/pcLpcqKir8+k+fPq3jx4/7xvyY3W6Xw+HwOwAAQPsV0IASFxcnl8ul/Px8X5vX61VxcbESExMlSYmJiaqsrFRJSYlvzLZt29TQ0KCEhIRAlgMAANqoZn+Kp6qqSl988YXv9sGDB7V3715FRkYqNjZW8+bN0+OPP66+ffsqLi5O2dnZio6O1tSpUyVJ8fHxmjBhgu644w6tWrVKdXV1ysjI0IwZM/gEDwAAkHQeAWXXrl26+uqrfbczMzMlSWlpaVqzZo0eeOABVVdXa86cOaqsrNTYsWO1detWhYaG+u7z2muvKSMjQ+PHj1dQUJCmT5+uZcuWBeB0AABAe2CzLMtq7SKay+v1yul0yuPxtMj1KL0XvnXOMYcWpwT8cQEAaM+a8/rdJj7FAwAALi4EFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAEPKPX19crOzlZcXJzCwsLUp08f/f73v5dlWb4xlmVp0aJF6tmzp8LCwpSUlKQDBw4EuhQAANBGBTygPPXUU1q5cqX+8Ic/qLS0VE899ZSefvppLV++3Dfm6aef1rJly7Rq1SoVFxerU6dOSk5OVk1NTaDLAQAAbVBwoCf88MMPNWXKFKWkpEiSevfurT/96U/asWOHpH/snixdulQPPfSQpkyZIkl69dVXFRUVpU2bNmnGjBmBLgkAALQxAd9BufLKK5Wfn6/PP/9ckvQ///M/ev/99zVx4kRJ0sGDB+V2u5WUlOS7j9PpVEJCgoqKihqds7a2Vl6v1+8AAADtV8B3UBYuXCiv16v+/furQ4cOqq+v1xNPPKHU1FRJktvtliRFRUX53S8qKsrX92M5OTl69NFHA10qAAAwVMB3UP7jP/5Dr732mtatW6fdu3dr7dq1WrJkidauXXvec2ZlZcnj8fiOsrKyAFYMAABME/AdlAULFmjhwoW+a0kGDRqkw4cPKycnR2lpaXK5XJKk8vJy9ezZ03e/8vJyDR06tNE57Xa77HZ7oEsFAACGCvgOysmTJxUU5D9thw4d1NDQIEmKi4uTy+VSfn6+r9/r9aq4uFiJiYmBLgcAALRBAd9BmTx5sp544gnFxsZq4MCB2rNnj5599lndfvvtkiSbzaZ58+bp8ccfV9++fRUXF6fs7GxFR0dr6tSpgS4HAAC0QQEPKMuXL1d2drZ+97vfqaKiQtHR0brzzju1aNEi35gHHnhA1dXVmjNnjiorKzV27Fht3bpVoaGhgS4HAAC0QTbrh1/x2kZ4vV45nU55PB45HI6Az9974VvnHHNocUrAHxcAgPasOa/f/BYPAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjBPc2gW0Vb0XvnXOMYcWp1yASgAAaH/YQQEAAMZhB6UFNWWXpSnYiQEAXGzYQQEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcVokoHz99de65ZZb1LVrV4WFhWnQoEHatWuXr9+yLC1atEg9e/ZUWFiYkpKSdODAgZYoBQAAtEEBDyjffvutxowZo44dO+rtt9/Wp59+qmeeeUZdunTxjXn66ae1bNkyrVq1SsXFxerUqZOSk5NVU1MT6HIAAEAbFPBfM37qqacUExOj3NxcX1tcXJzvz5ZlaenSpXrooYc0ZcoUSdKrr76qqKgobdq0STNmzAh0SQAAoI0J+A7Km2++qREjRuiGG25Qjx49NGzYML388su+/oMHD8rtdispKcnX5nQ6lZCQoKKiokbnrK2tldfr9TsAAED7FfCA8tVXX2nlypXq27ev/vrXv+ruu+/WPffco7Vr10qS3G63JCkqKsrvflFRUb6+H8vJyZHT6fQdMTExgS4bAAAYJOABpaGhQVdccYWefPJJDRs2THPmzNEdd9yhVatWnfecWVlZ8ng8vqOsrCyAFQMAANMEPKD07NlTAwYM8GuLj4/XkSNHJEkul0uSVF5e7jemvLzc1/djdrtdDofD7wAAAO1XwAPKmDFjtH//fr+2zz//XL169ZL0jwtmXS6X8vPzff1er1fFxcVKTEwMdDkAAKANCvineObPn68rr7xSTz75pG688Ubt2LFDL730kl566SVJks1m07x58/T444+rb9++iouLU3Z2tqKjozV16tRAlwMAANqggAeUkSNHauPGjcrKytJjjz2muLg4LV26VKmpqb4xDzzwgKqrqzVnzhxVVlZq7Nix2rp1q0JDQwNdDgAAaINslmVZrV1Ec3m9XjmdTnk8nha5HqX3wrcCPufPcWhxSmuXAADAz9ac129+iwcAABgn4G/xIPCasqPDLgsAoD1hBwUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDh8zPgiwseVAQBtBTsoAADAOOygtBOmfT0/AAA/BzsoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxmnxgLJ48WLZbDbNmzfP11ZTU6P09HR17dpV4eHhmj59usrLy1u6FAAA0Ea0aEDZuXOnXnzxRQ0ePNivff78+dq8ebPeeOMNFRQU6OjRo7ruuutashQAANCGtFhAqaqqUmpqql5++WV16dLF1+7xePTKK6/o2Wef1TXXXKPhw4crNzdXH374obZv397oXLW1tfJ6vX4HAABov1osoKSnpyslJUVJSUl+7SUlJaqrq/Nr79+/v2JjY1VUVNToXDk5OXI6nb4jJiampcoGAAAGaJGAsn79eu3evVs5OTln9LndboWEhCgiIsKvPSoqSm63u9H5srKy5PF4fEdZWVlLlA0AAAwRHOgJy8rKdO+99yovL0+hoaEBmdNut8tutwdkLgAAYL6A76CUlJSooqJCV1xxhYKDgxUcHKyCggItW7ZMwcHBioqK0qlTp1RZWel3v/LycrlcrkCXAwAA2qCA76CMHz9eH3/8sV/brFmz1L9/fz344IOKiYlRx44dlZ+fr+nTp0uS9u/fryNHjigxMTHQ5QAAgDYo4AGlc+fOuvzyy/3aOnXqpK5du/raZ8+erczMTEVGRsrhcGju3LlKTEzU6NGjA10Omqn3wrfOOebQ4pQLUAkA4GIW8IDSFM8995yCgoI0ffp01dbWKjk5WS+88EJrlAIAAAxksyzLau0imsvr9crpdMrj8cjhcAR8/qbsIlzM2EEBAJyP5rx+81s8AADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOMGtXQDant4L3zrnmEOLUy5AJQCA9oodFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4wQ8oOTk5GjkyJHq3LmzevTooalTp2r//v1+Y2pqapSenq6uXbsqPDxc06dPV3l5eaBLAQAAbVTAA0pBQYHS09O1fft25eXlqa6uTtdee62qq6t9Y+bPn6/NmzfrjTfeUEFBgY4eParrrrsu0KUAAIA2KuBf1LZ161a/22vWrFGPHj1UUlKiX/3qV/J4PHrllVe0bt06XXPNNZKk3NxcxcfHa/v27Ro9enSgSwIAAG1Mi1+D4vF4JEmRkZGSpJKSEtXV1SkpKck3pn///oqNjVVRUVGjc9TW1srr9fodAACg/WrRr7pvaGjQvHnzNGbMGF1++eWSJLfbrZCQEEVERPiNjYqKktvtbnSenJwcPfrooy1ZKgKsKV+HHyimfa2+aT8FYFo9ANAULbqDkp6erk8++UTr16//WfNkZWXJ4/H4jrKysgBVCAAATNRiOygZGRnasmWLCgsLdemll/raXS6XTp06pcrKSr9dlPLycrlcrkbnstvtstvtLVUqcNFjlwWAaQK+g2JZljIyMrRx40Zt27ZNcXFxfv3Dhw9Xx44dlZ+f72vbv3+/jhw5osTExECXAwAA2qCA76Ckp6dr3bp1+vOf/6zOnTv7ritxOp0KCwuT0+nU7NmzlZmZqcjISDkcDs2dO1eJiYl8ggfGu5DX1gDAxSzgAWXlypWSpHHjxvm15+bm6rbbbpMkPffccwoKCtL06dNVW1ur5ORkvfDCC4EuBQAAtFEBDyiWZZ1zTGhoqFasWKEVK1YE+uEBAEA70KIfMwYuhLZ4gSdvFZ1dW1xTAIHFjwUCAADjsIMCABcIO0NA07GDAgAAjMMOCi4KXPMBAG0LOygAAMA47KAAuKDYzQLQFOygAAAA4xBQAACAcQgoAADAOFyDAqBJLubv8DDt3E2rB2gJ7KAAAADjEFAAAIBxeIsHQJvE2xxA+8YOCgAAMA47KAACxrQvYWOXBWi72EEBAADGIaAAAADjEFAAAIBxuAYFwEUtUNfNtMXrb5qCa3TQWthBAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDh8zBgD8pAv5cwH8NAF+iB0UAABgHHZQAMAgpn3hG9Ba2EEBAADGYQcFANDiLvTOENeztH3soAAAAOOwgwIAaDMCuRPTFndZ2mLN56tVd1BWrFih3r17KzQ0VAkJCdqxY0drlgMAAAzRagHl9ddfV2Zmph5++GHt3r1bQ4YMUXJysioqKlqrJAAAYAibZVlWazxwQkKCRo4cqT/84Q+SpIaGBsXExGju3LlauHDhWe/r9XrldDrl8XjkcDgCXhsf8wMAtFVNeYuntd4qas7rd6tcg3Lq1CmVlJQoKyvL1xYUFKSkpCQVFRWdMb62tla1tbW+2x6PR9I/TrQlNNSebJF5AQBoaU15bWzK61xLvMZ+P2dT9kZaJaD8/e9/V319vaKiovzao6Ki9Nlnn50xPicnR48++ugZ7TExMS1WIwAAbZFzqVnzNObEiRNyOp1nHdMmPsWTlZWlzMxM3+2GhgYdP35cXbt2lc1mC8hjeL1excTEqKysrEXeNsLPw/qYjfUxG+tjtotpfSzL0okTJxQdHX3Osa0SULp166YOHTqovLzcr728vFwul+uM8Xa7XXa73a8tIiKiRWpzOBzt/i9IW8b6mI31MRvrY7aLZX3OtXPyvVb5FE9ISIiGDx+u/Px8X1tDQ4Py8/OVmJjYGiUBAACDtNpbPJmZmUpLS9OIESM0atQoLV26VNXV1Zo1a1ZrlQQAAAzRagHlpptu0jfffKNFixbJ7XZr6NCh2rp16xkXzl4odrtdDz/88BlvJcEMrI/ZWB+zsT5mY30a12rfgwIAAPBT+LFAAABgHAIKAAAwDgEFAAAYh4ACAACMQ0CRtGLFCvXu3VuhoaFKSEjQjh07Wruki0JhYaEmT56s6Oho2Ww2bdq0ya/fsiwtWrRIPXv2VFhYmJKSknTgwAG/McePH1dqaqocDociIiI0e/ZsVVVVXcCzaL9ycnI0cuRIde7cWT169NDUqVO1f/9+vzE1NTVKT09X165dFR4erunTp5/xBYxHjhxRSkqKLrnkEvXo0UMLFizQ6dOnL+SptEsrV67U4MGDfV/ulZiYqLffftvXz9qYZfHixbLZbJo3b56vjTU6u4s+oLz++uvKzMzUww8/rN27d2vIkCFKTk5WRUVFa5fW7lVXV2vIkCFasWJFo/1PP/20li1bplWrVqm4uFidOnVScnKyampqfGNSU1O1b98+5eXlacuWLSosLNScOXMu1Cm0awUFBUpPT9f27duVl5enuro6XXvttaqurvaNmT9/vjZv3qw33nhDBQUFOnr0qK677jpff319vVJSUnTq1Cl9+OGHWrt2rdasWaNFixa1xim1K5deeqkWL16skpIS7dq1S9dcc42mTJmiffv2SWJtTLJz5069+OKLGjx4sF87a3QO1kVu1KhRVnp6uu92fX29FR0dbeXk5LRiVRcfSdbGjRt9txsaGiyXy2X927/9m6+tsrLSstvt1p/+9CfLsizr008/tSRZO3fu9I15++23LZvNZn399dcXrPaLRUVFhSXJKigosCzrH+vRsWNH64033vCNKS0ttSRZRUVFlmVZ1l/+8hcrKCjIcrvdvjErV660HA6HVVtbe2FP4CLQpUsXa/Xq1ayNQU6cOGH17dvXysvLs6666irr3nvvtSyLfz9NcVHvoJw6dUolJSVKSkrytQUFBSkpKUlFRUWtWBkOHjwot9vttzZOp1MJCQm+tSkqKlJERIRGjBjhG5OUlKSgoCAVFxdf8JrbO4/HI0mKjIyUJJWUlKiurs5vjfr376/Y2Fi/NRo0aJDfFzAmJyfL6/X6/qePn6++vl7r169XdXW1EhMTWRuDpKenKyUlxW8tJP79NEWb+DXjlvL3v/9d9fX1Z3x7bVRUlD777LNWqgqS5Ha7JanRtfm+z+12q0ePHn79wcHBioyM9I1BYDQ0NGjevHkaM2aMLr/8ckn/eP5DQkLO+OHOH69RY2v4fR9+no8//liJiYmqqalReHi4Nm7cqAEDBmjv3r2sjQHWr1+v3bt3a+fOnWf08e/n3C7qgAKgadLT0/XJJ5/o/fffb+1S8AP9+vXT3r175fF49J//+Z9KS0tTQUFBa5cFSWVlZbr33nuVl5en0NDQ1i6nTbqo3+Lp1q2bOnTocMZV0+Xl5XK5XK1UFST5nv+zrY3L5TrjYubTp0/r+PHjrF8AZWRkaMuWLXr33Xd16aWX+tpdLpdOnTqlyspKv/E/XqPG1vD7Pvw8ISEh+sUvfqHhw4crJydHQ4YM0fPPP8/aGKCkpEQVFRW64oorFBwcrODgYBUUFGjZsmUKDg5WVFQUa3QOF3VACQkJ0fDhw5Wfn+9ra2hoUH5+vhITE1uxMsTFxcnlcvmtjdfrVXFxsW9tEhMTVVlZqZKSEt+Ybdu2qaGhQQkJCRe85vbGsixlZGRo48aN2rZtm+Li4vz6hw8fro4dO/qt0f79+3XkyBG/Nfr444/9gmReXp4cDocGDBhwYU7kItLQ0KDa2lrWxgDjx4/Xxx9/rL179/qOESNGKDU11fdn1ugcWvsq3da2fv16y263W2vWrLE+/fRTa86cOVZERITfVdNoGSdOnLD27Nlj7dmzx5JkPfvss9aePXusw4cPW5ZlWYsXL7YiIiKsP//5z9ZHH31kTZkyxYqLi7O+++473xwTJkywhg0bZhUXF1vvv/++1bdvX+vmm29urVNqV+6++27L6XRa7733nnXs2DHfcfLkSd+Yu+66y4qNjbW2bdtm7dq1y0pMTLQSExN9/adPn7Yuv/xy69prr7X27t1rbd261erevbuVlZXVGqfUrixcuNAqKCiwDh48aH300UfWwoULLZvNZr3zzjuWZbE2Jvrhp3gsizU6l4s+oFiWZS1fvtyKjY21QkJCrFGjRlnbt29v7ZIuCu+++64l6YwjLS3Nsqx/fNQ4OzvbioqKsux2uzV+/Hhr//79fnP83//9n3XzzTdb4eHhlsPhsGbNmmWdOHGiFc6m/WlsbSRZubm5vjHfffed9bvf/c7q0qWLdckll1jTpk2zjh075jfPoUOHrIkTJ1phYWFWt27drPvuu8+qq6u7wGfT/tx+++1Wr169rJCQEKt79+7W+PHjfeHEslgbE/04oLBGZ2ezLMtqnb0bAACAxl3U16AAAAAzEVAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoACQJK1Zs+aMn35H63nkkUc0dOjQ1i4DaDUEFOACue2222Sz2XTXXXed0Zeeni6bzabbbrutWXPabDZt2rSp2bX07t1bS5cu9Wu76aab9Pnnnzd7rrZs48aNGj16tJxOpzp37qyBAwdq3rx5rV0WABFQgAsqJiZG69ev13fffedrq6mp0bp16xQbG9uKlUlhYWHq0aNHq9bQEurr69XQ0HBGe35+vm666SZNnz5dO3bsUElJiZ544gnV1dW1QpUAfoyAAlxAV1xxhWJiYrRhwwZf24YNGxQbG6thw4b5jW1sl2Po0KF65JFHfP2SNG3aNNlsNt/tL7/8UlOmTFFUVJTCw8M1cuRI/e1vf/PNMW7cOB0+fFjz58+XzWaTzWaT1PhbPCtXrlSfPn0UEhKifv366Y9//KNfv81m0+rVqzVt2jRdcskl6tu3r958801f/7fffqvU1FR1795dYWFh6tu3r3Jzc3/y+Rk3bpwyMjKUkZEhp9Opbt26KTs7Wz/8ybDa2lrdf//9+qd/+id16tRJCQkJeu+993z935/Hm2++qQEDBshut+vIkSNnPNbmzZs1ZswYLViwQP369dNll12mqVOnasWKFb4x53ouv1+Hxx9/XDNnzlR4eLh69eqlN998U998842mTJmi8PBwDR48WLt27Tqjxk2bNqlv374KDQ1VcnKyysrKfvK5kaTVq1crPj5eoaGh6t+/v1544YWzjgfaMgIKcIHdfvvtfi/S//7v/65Zs2Y1e56dO3dKknJzc3Xs2DHf7aqqKk2aNEn5+fnas2ePJkyYoMmTJ/tepDds2KBLL71Ujz32mI4dO6Zjx441Ov/GjRt177336r777tMnn3yiO++8U7NmzdK7777rN+7RRx/VjTfeqI8++kiTJk1Samqqjh8/LknKzs7Wp59+qrffflulpaVauXKlunXrdtbzWrt2rYKDg7Vjxw49//zzevbZZ7V69Wpff0ZGhoqKirR+/Xp99NFHuuGGGzRhwgQdOHDAN+bkyZN66qmntHr1au3bt6/RnSGXy6V9+/bpk08++clazvVcfu+5557TmDFjtGfPHqWkpOjWW2/VzJkzdcstt2j37t3q06ePZs6c6Re0Tp48qSeeeEKvvvqqPvjgA1VWVmrGjBk/Wctrr72mRYsW6YknnlBpaamefPJJZWdna+3atWd9PoE2q3V/TBm4eKSlpVlTpkyxKioqLLvdbh06dMg6dOiQFRoaan3zzTfWlClTrLS0NN/4Xr16Wc8995zfHEOGDLEefvhh321J1saNG8/52AMHDrSWL19+1rlzc3Mtp9Ppu33llVdad9xxh9+YG264wZo0aZLf4z/00EO+21VVVZYk6+2337Ysy7ImT55szZo165z1fe+qq66y4uPjrYaGBl/bgw8+aMXHx1uWZVmHDx+2OnToYH399dd+9xs/fryVlZXlOw9J1t69e8/6WFVVVdakSZMsSVavXr2sm266yXrllVesmpqas96vsefylltu8d0+duyYJcnKzs72tRUVFVmSrGPHjvnVuH37dt+Y0tJSS5JVXFxsWZZlPfzww9aQIUN8/X369LHWrVvnV8vvf/97KzEx8az1Am0VOyjABda9e3elpKRozZo1ys3NVUpKyjl3FZqjqqpK999/v+Lj4xUREaHw8HCVlpY2+jbH2ZSWlmrMmDF+bWPGjFFpaalf2+DBg31/7tSpkxwOhyoqKiRJd999t9avX6+hQ4fqgQce0IcffnjOxx09erTvbSdJSkxM1IEDB1RfX6+PP/5Y9fX1uuyyyxQeHu47CgoK9OWXX/ruExIS4ldXYzp16qS33npLX3zxhR566CGFh4frvvvu06hRo3Ty5ElJTX8uf/hYUVFRkqRBgwad0fb98yJJwcHBGjlypO92//79FRERccbzK0nV1dX68ssvNXv2bL/zfvzxx/3OG2hPglu7AOBidPvttysjI0OS/K55+KGgoCC/twQkNekCzvvvv195eXlasmSJfvGLXygsLEzXX3+9Tp069fMLb0THjh39bttsNt9FqRMnTtThw4f1l7/8RXl5eRo/frzS09O1ZMmS83qsqqoqdejQQSUlJerQoYNfX3h4uO/PYWFhfiHnbPr06aM+ffrot7/9rf71X/9Vl112mV5//XXNmjWryc/lD5+D7x+3sbbGLtZtiqqqKknSyy+/rISEBL++Hz8PQHtBQAFawYQJE3Tq1CnZbDYlJyc3OqZ79+5+14d4vV4dPHjQb0zHjh1VX1/v1/bBBx/otttu07Rp0yT948Xt0KFDfmNCQkLOuN+PxcfH64MPPlBaWprf3AMGDDjn+f34PNLS0pSWlqZf/vKXWrBgwVkDSnFxsd/t7du3q2/fvurQoYOGDRum+vp6VVRU6Je//GWz6miK3r1765JLLlF1dbWkpj2X5+v06dPatWuXRo0aJUnav3+/KisrFR8ff8bYqKgoRUdH66uvvlJqampAHh8wHQEFaAUdOnTwbeX/1P+Ar7nmGq1Zs0aTJ09WRESEFi1adMbY3r17Kz8/X2PGjJHdbleXLl3Ut29fbdiwQZMnT5bNZlN2dvYZ/3Pv3bu3CgsLNWPGDNnt9kbfYlqwYIFuvPFGDRs2TElJSdq8ebM2bNhwxqdYzmbRokUaPny4Bg4cqNraWm3ZsqXRF+AfOnLkiDIzM3XnnXdq9+7dWr58uZ555hlJ0mWXXabU1FTNnDlTzzzzjIYNG6ZvvvlG+fn5Gjx4sFJSUppc2yOPPKKTJ09q0qRJ6tWrlyorK7Vs2TLV1dXpn//5nyWpSc/l+erYsaPmzp2rZcuWKTg4WBkZGRo9erQvsPzYo48+qnvuuUdOp1MTJkxQbW2tdu3apW+//VaZmZkBqQkwCdegAK3E4XDI4XD8ZH9WVpauuuoq/frXv1ZKSoqmTp2qPn36+I155plnlJeXp5iYGN/HlJ999ll16dJFV155pSZPnqzk5GRdccUVfvd77LHHdOjQIfXp00fdu3dv9PGnTp2q559/XkuWLNHAgQP14osvKjc3V+PGjWvyOYaEhCgrK0uDBw/Wr371K3Xo0EHr168/631mzpyp7777TqNGjVJ6erruvfdezZkzx9efm5urmTNn6r777lO/fv00depU7dy5s9nfI3PVVVfpq6++0syZM9W/f39NnDhRbrdb77zzjvr16yepac/l+brkkkv04IMP6l/+5V80ZswYhYeH6/XXX//J8b/97W+1evVq5ebmatCgQbrqqqu0Zs0axcXFBaQewDQ268dvcgNAKxk3bpyGDh16xve/tDdr1qzRvHnzVFlZ2dqlAMZiBwUAABiHgAIAAIzDWzwAAMA47KAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMb5f5mY+VBZT8SeAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.unique(instances['sample_idx'], return_counts=True)[1], bins=50)\n",
    "plt.xlabel('Mutations per Sample')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'T' 'G' 'C' 'C' 'T']\n",
      " ['G' 'A' 'T' 'T' 'T' 'A']\n",
      " ['T' 'T' 'T' 'C' 'T' 'T']\n",
      " ['G' 'C' 'A' 'G' 'C' 'A']\n",
      " ['A' 'T' 'A' 'T' 'A' 'A']\n",
      " ['A' 'T' 'C' 'G' 'G' 'G']\n",
      " ['G' 'A' 'G' 'T' 'C' 'A']\n",
      " ['T' 'T' 'C' 'C' 'A' 'A']\n",
      " ['A' 'C' 'A' 'G' 'G' 'T']\n",
      " ['C' 'T' 'G' 'C' 'A' 'C']]\n"
     ]
    }
   ],
   "source": [
    "print(instances['seq_5p'][instances['class'] == 0][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']]\n"
     ]
    }
   ],
   "source": [
    "print(instances['seq_5p'][instances['class'] == 1][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The negative instances have random sequences 5' of the mutation as expected while the positive instances all have the same sequence.  We need to convert from nucleotide to a format the model can use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "nucleotide_mapping = {'-': 0, 'N': 0, 'A': 1, 'T': 2, 'C': 3, 'G': 4}\n",
    "instances['seq_5p'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_5p']), axis=0)\n",
    "instances['seq_3p'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_3p']), axis=0)\n",
    "instances['seq_ref'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_ref']), axis=0)\n",
    "instances['seq_alt'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_alt']), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The model will onehot this encoded data on the graph.  We need to stack the reverse of a variant with its forward counterpart to fully represent a variant."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "variant_encoding = np.array([0, 2, 1, 4, 3])\n",
    "instances['seq_5p'] = np.stack([instances['seq_5p'], variant_encoding[instances['seq_3p'][:, ::-1]]], axis=2)\n",
    "instances['seq_3p'] = np.stack([instances['seq_3p'], variant_encoding[instances['seq_5p'][:, :, 0][:, ::-1]]], axis=2)\n",
    "t = instances['seq_ref'].copy()\n",
    "i = t != 0\n",
    "t[i] = variant_encoding[instances['seq_ref'][:, ::-1]][i[:, ::-1]]\n",
    "instances['seq_ref'] = np.stack([instances['seq_ref'], t], axis=2)\n",
    "t = instances['seq_alt'].copy()\n",
    "i = t != 0\n",
    "t[i] = variant_encoding[instances['seq_alt'][:, ::-1]][i[:, ::-1]]\n",
    "instances['seq_alt'] = np.stack([instances['seq_alt'], t], axis=2)\n",
    "del i, t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will onehot the strand ourselves, but it could have been done on graph."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "strand_emb_mat = np.concatenate([np.zeros(2)[np.newaxis, :], np.diag(np.ones(2))], axis=0)\n",
    "instances['strand_emb'] = strand_emb_mat[instances['strand']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#We need to construct a ragged NumPy array using the sample indexes.  Using sample indexes allows for the possibility that the instances are not in order, for example instance of sample 1, instance of sample 2, instance of sample 1.  If you know that your data is in order then this operation could be done far more efficiently."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "indexes = [np.where(instances['sample_idx'] == idx) for idx in range(len(samples['classes']))]\n",
    "five_p = np.array([instances['seq_5p'][i] for i in indexes], dtype='object')\n",
    "three_p = np.array([instances['seq_3p'][i] for i in indexes], dtype='object')\n",
    "ref = np.array([instances['seq_ref'][i] for i in indexes], dtype='object')\n",
    "alt = np.array([instances['seq_alt'][i] for i in indexes], dtype='object')\n",
    "strand = np.array([instances['strand_emb'][i] for i in indexes], dtype='object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#In order to provide the graph ragged tensors we use loaders.  The loaders will automatically infer that ragged tensors need to be made from the fact that the arrays are dtype object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "five_p_loader = DatasetsUtils.Map.FromNumpy(five_p, tf.int32)\n",
    "three_p_loader = DatasetsUtils.Map.FromNumpy(three_p, tf.int32)\n",
    "ref_loader = DatasetsUtils.Map.FromNumpy(ref, tf.int32)\n",
    "alt_loader = DatasetsUtils.Map.FromNumpy(alt, tf.int32)\n",
    "strand_loader = DatasetsUtils.Map.FromNumpy(strand, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##A loader is not needed for data which will not be converted into a ragged tensor but can still be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "y_label = np.array(samples['classes'])[:, np.newaxis]\n",
    "y_strat = y_label\n",
    "y_label_loader = DatasetsUtils.Map.FromNumpy(y_label, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "idx_train, idx_test = next(StratifiedShuffleSplit(random_state=0, n_splits=1, test_size=200).split(y_strat, y_strat))\n",
    "idx_train, idx_valid = [idx_train[idx] for idx in list(StratifiedShuffleSplit(n_splits=1, test_size=300, random_state=0).split(np.zeros_like(y_strat)[idx_train], y_strat[idx_train]))[0]]\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((idx_train, y_strat[idx_train]))\n",
    "ds_train = ds_train.apply(DatasetsUtils.Apply.StratifiedMinibatch(batch_size=100, ds_size=len(idx_train)))\n",
    "ds_train = ds_train.map(lambda x: ((five_p_loader(x),\n",
    "                                    three_p_loader(x),\n",
    "                                    ref_loader(x),\n",
    "                                    alt_loader(x),\n",
    "                                    strand_loader(x)),\n",
    "                                    y_label_loader(x)\n",
    "                                   ))\n",
    "\n",
    "\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(((five_p_loader(idx_valid),\n",
    "                                                three_p_loader(idx_valid),\n",
    "                                                ref_loader(idx_valid),\n",
    "                                                alt_loader(idx_valid),\n",
    "                                                strand_loader(idx_valid),\n",
    "                                                ),\n",
    "                                               tf.gather(y_label, idx_valid),\n",
    "                                               ))\n",
    "ds_valid = ds_valid.batch(len(idx_valid), drop_remainder=False)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(((five_p_loader(idx_test),\n",
    "                                                three_p_loader(idx_test),\n",
    "                                                ref_loader(idx_test),\n",
    "                                                alt_loader(idx_test),\n",
    "                                                strand_loader(idx_test),\n",
    "                                                ),\n",
    "                                               tf.gather(y_label, idx_test),\n",
    "                                               ))\n",
    "ds_test = ds_test.batch(len(idx_test), drop_remainder=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#We need to build our sequence encoder.  The sequences are 6 nucleotides long, have an embedding dimension of 4, and have 2 strands.  We will use 16 kernels for the 5' and 3' sequences, and 8 kernels for the ref and alt sequences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "tile_encoder = InstanceModels.VariantSequence(6, 4, 2, [16, 16, 8, 8])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#We will build our MIL model with the default parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "mil = RaggedModels.MIL(instance_encoders=[tile_encoder.model])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 16:58:19.535310: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 206ms/step - loss: 1.5316 - accuracy: 0.4784 - binary_crossentropy: 0.9080 - val_loss: 1.2865 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6897\n",
      "Epoch 2/10000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.2582 - accuracy: 0.4772 - binary_crossentropy: 0.6815 - val_loss: 1.2238 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6702\n",
      "Epoch 3/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2030 - accuracy: 0.4784 - binary_crossentropy: 0.6657 - val_loss: 1.1695 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6508\n",
      "Epoch 4/10000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 1.1563 - accuracy: 0.4784 - binary_crossentropy: 0.6512 - val_loss: 1.1239 - val_accuracy: 0.4833 - val_binary_crossentropy: 0.6344\n",
      "Epoch 5/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.1044 - accuracy: 0.5360 - binary_crossentropy: 0.6265 - val_loss: 1.0663 - val_accuracy: 0.5333 - val_binary_crossentropy: 0.6017\n",
      "Epoch 6/10000\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 1.0505 - accuracy: 0.5829 - binary_crossentropy: 0.5954 - val_loss: 1.0026 - val_accuracy: 0.6800 - val_binary_crossentropy: 0.5580\n",
      "Epoch 7/10000\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.9830 - accuracy: 0.6727 - binary_crossentropy: 0.5449 - val_loss: 0.9141 - val_accuracy: 0.7533 - val_binary_crossentropy: 0.4826\n",
      "Epoch 8/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9077 - accuracy: 0.7566 - binary_crossentropy: 0.4792 - val_loss: 0.8199 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3941\n",
      "Epoch 9/10000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8131 - accuracy: 0.8293 - binary_crossentropy: 0.3901 - val_loss: 0.7336 - val_accuracy: 0.8967 - val_binary_crossentropy: 0.3149\n",
      "Epoch 10/10000\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.7437 - accuracy: 0.8561 - binary_crossentropy: 0.3305 - val_loss: 0.6527 - val_accuracy: 0.9033 - val_binary_crossentropy: 0.2478\n",
      "Epoch 11/10000\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.6790 - accuracy: 0.8777 - binary_crossentropy: 0.2829 - val_loss: 0.5962 - val_accuracy: 0.9433 - val_binary_crossentropy: 0.2090\n",
      "Epoch 12/10000\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6136 - accuracy: 0.8942 - binary_crossentropy: 0.2340 - val_loss: 0.5554 - val_accuracy: 0.9633 - val_binary_crossentropy: 0.1835\n",
      "Epoch 13/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.5654 - accuracy: 0.9329 - binary_crossentropy: 0.2014 - val_loss: 0.4936 - val_accuracy: 0.9633 - val_binary_crossentropy: 0.1375\n",
      "Epoch 14/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.5157 - accuracy: 0.9472 - binary_crossentropy: 0.1652 - val_loss: 0.4571 - val_accuracy: 0.9800 - val_binary_crossentropy: 0.1121\n",
      "Epoch 15/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4775 - accuracy: 0.9579 - binary_crossentropy: 0.1383 - val_loss: 0.4266 - val_accuracy: 0.9833 - val_binary_crossentropy: 0.0943\n",
      "Epoch 16/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4426 - accuracy: 0.9676 - binary_crossentropy: 0.1158 - val_loss: 0.4038 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0834\n",
      "Epoch 17/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.4236 - accuracy: 0.9640 - binary_crossentropy: 0.1097 - val_loss: 0.3896 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0790\n",
      "Epoch 18/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3966 - accuracy: 0.9736 - binary_crossentropy: 0.0929 - val_loss: 0.3730 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0729\n",
      "Epoch 19/10000\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3831 - accuracy: 0.9724 - binary_crossentropy: 0.0906 - val_loss: 0.3466 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0607\n",
      "Epoch 20/10000\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3701 - accuracy: 0.9760 - binary_crossentropy: 0.0873 - val_loss: 0.3327 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0542\n",
      "Epoch 21/10000\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3436 - accuracy: 0.9796 - binary_crossentropy: 0.0675 - val_loss: 0.3255 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0535\n",
      "Epoch 22/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.3356 - accuracy: 0.9784 - binary_crossentropy: 0.0692 - val_loss: 0.3150 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0511\n",
      "Epoch 23/10000\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.3208 - accuracy: 0.9868 - binary_crossentropy: 0.0616 - val_loss: 0.2997 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0455\n",
      "Epoch 24/10000\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.3107 - accuracy: 0.9856 - binary_crossentropy: 0.0606 - val_loss: 0.2886 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0433\n",
      "Epoch 25/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3001 - accuracy: 0.9808 - binary_crossentropy: 0.0582 - val_loss: 0.2910 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0489\n",
      "Epoch 26/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2896 - accuracy: 0.9856 - binary_crossentropy: 0.0550 - val_loss: 0.2705 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0393\n",
      "Epoch 27/10000\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2797 - accuracy: 0.9904 - binary_crossentropy: 0.0519 - val_loss: 0.2637 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0384\n",
      "Epoch 28/10000\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2646 - accuracy: 0.9892 - binary_crossentropy: 0.0446 - val_loss: 0.2538 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0362\n",
      "Epoch 29/10000\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2648 - accuracy: 0.9904 - binary_crossentropy: 0.0496 - val_loss: 0.2450 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0350\n",
      "Epoch 30/10000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2481 - accuracy: 0.9904 - binary_crossentropy: 0.0405 - val_loss: 0.2402 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0349\n",
      "Epoch 31/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2419 - accuracy: 0.9904 - binary_crossentropy: 0.0411 - val_loss: 0.2347 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0346\n",
      "Epoch 32/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.2331 - accuracy: 0.9904 - binary_crossentropy: 0.0389 - val_loss: 0.2266 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0324\n",
      "Epoch 33/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2292 - accuracy: 0.9904 - binary_crossentropy: 0.0392 - val_loss: 0.2189 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0313\n",
      "Epoch 34/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.2195 - accuracy: 0.9916 - binary_crossentropy: 0.0356 - val_loss: 0.2105 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0299\n",
      "Epoch 35/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.2141 - accuracy: 0.9904 - binary_crossentropy: 0.0358 - val_loss: 0.2033 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0283\n",
      "Epoch 36/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2041 - accuracy: 0.9940 - binary_crossentropy: 0.0307 - val_loss: 0.1989 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0280\n",
      "Epoch 37/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2017 - accuracy: 0.9904 - binary_crossentropy: 0.0342 - val_loss: 0.1918 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0272\n",
      "Epoch 38/10000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.1904 - accuracy: 0.9976 - binary_crossentropy: 0.0274 - val_loss: 0.1866 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0260\n",
      "Epoch 39/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.1856 - accuracy: 0.9940 - binary_crossentropy: 0.0285 - val_loss: 0.1842 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0269\n",
      "Epoch 40/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1815 - accuracy: 0.9940 - binary_crossentropy: 0.0290 - val_loss: 0.1795 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0269\n",
      "Epoch 41/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1727 - accuracy: 0.9964 - binary_crossentropy: 0.0234 - val_loss: 0.1709 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0256\n",
      "Epoch 42/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1714 - accuracy: 0.9928 - binary_crossentropy: 0.0261 - val_loss: 0.1664 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0261\n",
      "Epoch 43/10000\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1655 - accuracy: 0.9952 - binary_crossentropy: 0.0247 - val_loss: 0.1659 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0240\n",
      "Epoch 44/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.1617 - accuracy: 0.9940 - binary_crossentropy: 0.0242 - val_loss: 0.1582 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0226\n",
      "Epoch 45/10000\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1542 - accuracy: 0.9964 - binary_crossentropy: 0.0213 - val_loss: 0.1548 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0226\n",
      "Epoch 46/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.1493 - accuracy: 0.9988 - binary_crossentropy: 0.0206 - val_loss: 0.1504 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0220\n",
      "Epoch 47/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1434 - accuracy: 0.9988 - binary_crossentropy: 0.0186 - val_loss: 0.1460 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0221\n",
      "Epoch 48/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1428 - accuracy: 1.0000 - binary_crossentropy: 0.0199 - val_loss: 0.1421 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0229\n",
      "Epoch 49/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.1372 - accuracy: 0.9988 - binary_crossentropy: 0.0193 - val_loss: 0.1389 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0219\n",
      "Epoch 50/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1310 - accuracy: 0.9988 - binary_crossentropy: 0.0165 - val_loss: 0.1359 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0211\n",
      "Epoch 51/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1293 - accuracy: 1.0000 - binary_crossentropy: 0.0169 - val_loss: 0.1318 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0209\n",
      "Epoch 52/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1273 - accuracy: 0.9988 - binary_crossentropy: 0.0181 - val_loss: 0.1314 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0214\n",
      "Epoch 53/10000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1243 - accuracy: 0.9976 - binary_crossentropy: 0.0179 - val_loss: 0.1248 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 54/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1190 - accuracy: 1.0000 - binary_crossentropy: 0.0138 - val_loss: 0.1239 - val_accuracy: 0.9900 - val_binary_crossentropy: 0.0238\n",
      "Epoch 55/10000\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1173 - accuracy: 0.9976 - binary_crossentropy: 0.0146 - val_loss: 0.1199 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0196\n",
      "Epoch 56/10000\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.1130 - accuracy: 0.9976 - binary_crossentropy: 0.0159 - val_loss: 0.1232 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0225\n",
      "Epoch 57/10000\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1102 - accuracy: 1.0000 - binary_crossentropy: 0.0139 - val_loss: 0.1154 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0195\n",
      "Epoch 58/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1054 - accuracy: 1.0000 - binary_crossentropy: 0.0118 - val_loss: 0.1122 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0201\n",
      "Epoch 59/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1040 - accuracy: 1.0000 - binary_crossentropy: 0.0133 - val_loss: 0.1099 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0204\n",
      "Epoch 60/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1002 - accuracy: 1.0000 - binary_crossentropy: 0.0122 - val_loss: 0.1076 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0199\n",
      "Epoch 61/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0983 - accuracy: 1.0000 - binary_crossentropy: 0.0120 - val_loss: 0.1053 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0197\n",
      "Epoch 62/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0948 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 0.1039 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0199\n",
      "Epoch 63/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0930 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 0.1008 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 64/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0901 - accuracy: 1.0000 - binary_crossentropy: 0.0103 - val_loss: 0.0986 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 65/10000\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0882 - accuracy: 1.0000 - binary_crossentropy: 0.0106 - val_loss: 0.0969 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 66/10000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.0860 - accuracy: 1.0000 - binary_crossentropy: 0.0101 - val_loss: 0.0953 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0195\n",
      "Epoch 67/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0832 - accuracy: 1.0000 - binary_crossentropy: 0.0095 - val_loss: 0.0934 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0192\n",
      "Epoch 68/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0824 - accuracy: 1.0000 - binary_crossentropy: 0.0098 - val_loss: 0.0922 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0194\n",
      "Epoch 69/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0793 - accuracy: 1.0000 - binary_crossentropy: 0.0092 - val_loss: 0.0902 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0194\n",
      "Epoch 70/10000\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.0780 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 0.0893 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 71/10000\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0761 - accuracy: 1.0000 - binary_crossentropy: 0.0089 - val_loss: 0.0863 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0196\n",
      "Epoch 72/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0733 - accuracy: 1.0000 - binary_crossentropy: 0.0082 - val_loss: 0.0852 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 73/10000\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0713 - accuracy: 1.0000 - binary_crossentropy: 0.0079 - val_loss: 0.0829 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0193\n",
      "Epoch 74/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0712 - accuracy: 1.0000 - binary_crossentropy: 0.0088 - val_loss: 0.0843 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0207\n",
      "Epoch 75/10000\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.0692 - accuracy: 1.0000 - binary_crossentropy: 0.0079 - val_loss: 0.0803 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 76/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0669 - accuracy: 1.0000 - binary_crossentropy: 0.0072 - val_loss: 0.0788 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 77/10000\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0656 - accuracy: 1.0000 - binary_crossentropy: 0.0077 - val_loss: 0.0786 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 78/10000\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0640 - accuracy: 1.0000 - binary_crossentropy: 0.0075 - val_loss: 0.0773 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0201\n",
      "Epoch 79/10000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.0624 - accuracy: 1.0000 - binary_crossentropy: 0.0071 - val_loss: 0.0753 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0196\n",
      "Epoch 80/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0608 - accuracy: 1.0000 - binary_crossentropy: 0.0068 - val_loss: 0.0737 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 81/10000\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0597 - accuracy: 1.0000 - binary_crossentropy: 0.0065 - val_loss: 0.0728 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 82/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0583 - accuracy: 1.0000 - binary_crossentropy: 0.0066 - val_loss: 0.0709 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0198\n",
      "Epoch 83/10000\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0574 - accuracy: 1.0000 - binary_crossentropy: 0.0064 - val_loss: 0.0716 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0202\n",
      "Epoch 84/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0564 - accuracy: 1.0000 - binary_crossentropy: 0.0069 - val_loss: 0.0710 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0201\n",
      "Epoch 85/10000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.0555 - accuracy: 1.0000 - binary_crossentropy: 0.0062 - val_loss: 0.0691 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 86/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0544 - accuracy: 1.0000 - binary_crossentropy: 0.0070 - val_loss: 0.0680 - val_accuracy: 0.9900 - val_binary_crossentropy: 0.0216\n",
      "Epoch 87/10000\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0571 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 0.0819 - val_accuracy: 0.9833 - val_binary_crossentropy: 0.0387\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1144 - accuracy: 0.9900 - binary_crossentropy: 0.0351\n"
     ]
    }
   ],
   "source": [
    "losses = [tf.keras.losses.BinaryCrossentropy(from_logits=True)]\n",
    "mil.model.compile(loss=losses,\n",
    "                  metrics=['accuracy', tf.keras.metrics.BinaryCrossentropy(from_logits=True)],\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                ))\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', min_delta=0.00001, patience=20, mode='min', restore_best_weights=True)]\n",
    "history = mil.model.fit(ds_train, steps_per_epoch=10, validation_data=ds_valid, epochs=10000, callbacks=callbacks)\n",
    "evaluation = mil.model.evaluate(ds_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Check the performance on test data, this model achieved 99% accuracy on this task."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11439504474401474, 0.9900000095367432, 0.035059455782175064]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#To get the attention we call a separate model which was built by default."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "attention = mil.attention_model.predict(ds_test).to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The attention is a list per sample."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([1.841e+03, 5.902e+03, 2.963e+03, 7.680e+02, 2.280e+02, 1.850e+02,\n        1.650e+02, 7.500e+01, 4.500e+01, 1.500e+01, 7.000e+00, 7.000e+00,\n        8.000e+00, 6.000e+00, 1.100e+01, 1.400e+01, 1.300e+01, 1.200e+01,\n        2.000e+01, 1.000e+01, 2.200e+01, 2.100e+01, 2.200e+01, 1.800e+01,\n        2.000e+01, 2.700e+01, 2.600e+01, 3.700e+01, 3.000e+01, 3.100e+01,\n        4.100e+01, 4.700e+01, 5.000e+01, 6.500e+01, 4.700e+01, 6.600e+01,\n        6.000e+01, 6.700e+01, 7.700e+01, 8.500e+01, 5.700e+01, 9.300e+01,\n        8.800e+01, 9.800e+01, 1.170e+02, 1.230e+02, 1.320e+02, 1.600e+02,\n        1.480e+02, 1.520e+02, 1.390e+02, 1.400e+02, 1.380e+02, 1.580e+02,\n        1.680e+02, 1.640e+02, 1.560e+02, 1.760e+02, 1.460e+02, 1.550e+02,\n        1.410e+02, 1.470e+02, 1.530e+02, 1.480e+02, 1.270e+02, 1.290e+02,\n        1.380e+02, 1.210e+02, 1.380e+02, 9.800e+01, 1.070e+02, 9.200e+01,\n        7.700e+01, 8.500e+01, 6.500e+01, 7.000e+01, 6.200e+01, 6.400e+01,\n        6.400e+01, 4.400e+01, 3.900e+01, 4.100e+01, 3.800e+01, 3.500e+01,\n        3.200e+01, 1.700e+01, 1.300e+01, 2.200e+01, 2.000e+01, 1.100e+01,\n        1.700e+01, 1.600e+01, 8.000e+00, 1.600e+01, 3.000e+00, 8.000e+00,\n        2.000e+00, 2.000e+00, 3.000e+00, 2.000e+00]),\n array([0.0152351 , 0.02073604, 0.02623697, 0.03173791, 0.03723885,\n        0.04273979, 0.04824073, 0.05374166, 0.0592426 , 0.06474354,\n        0.07024448, 0.07574542, 0.08124635, 0.08674729, 0.09224823,\n        0.09774917, 0.10325011, 0.10875104, 0.11425198, 0.11975292,\n        0.12525386, 0.1307548 , 0.13625573, 0.14175667, 0.14725761,\n        0.15275855, 0.15825949, 0.16376042, 0.16926136, 0.1747623 ,\n        0.18026324, 0.18576418, 0.19126511, 0.19676605, 0.20226699,\n        0.20776793, 0.21326887, 0.2187698 , 0.22427074, 0.22977168,\n        0.23527262, 0.24077356, 0.24627449, 0.25177543, 0.25727637,\n        0.26277731, 0.26827825, 0.27377918, 0.27928012, 0.28478106,\n        0.290282  , 0.29578294, 0.30128387, 0.30678481, 0.31228575,\n        0.31778669, 0.32328763, 0.32878856, 0.3342895 , 0.33979044,\n        0.34529138, 0.35079232, 0.35629325, 0.36179419, 0.36729513,\n        0.37279607, 0.37829701, 0.38379794, 0.38929888, 0.39479982,\n        0.40030076, 0.40580169, 0.41130263, 0.41680357, 0.42230451,\n        0.42780545, 0.43330638, 0.43880732, 0.44430826, 0.4498092 ,\n        0.45531014, 0.46081107, 0.46631201, 0.47181295, 0.47731389,\n        0.48281483, 0.48831576, 0.4938167 , 0.49931764, 0.50481858,\n        0.51031952, 0.51582045, 0.52132139, 0.52682233, 0.53232327,\n        0.53782421, 0.54332514, 0.54882608, 0.55432702, 0.55982796,\n        0.5653289 ]),\n <BarContainer object of 100 artists>)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.concatenate(attention), bins=100)\n",
    "plt.xlabel('Attention')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#As we can see most instances received low attention while some received higher attention."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}