{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from figures.controls.samples.sim_data.sim_data_tools import *\n",
    "import pylab as plt\n",
    "import tensorflow as tf\n",
    "from model.Sample_MIL import InstanceModels, RaggedModels\n",
    "from model import DatasetsUtils\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[-1], True)\n",
    "tf.config.experimental.set_visible_devices(physical_devices[-1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Let's create some simulated mutation data where the positive class is defined by having mutations with a specific sequence 5' of the mutation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def generate_sample(mean_variants=[5, 10, 20, 30, 40, 50, 70, 100, 150, 200, 250, 300],\n",
    "                    control=True, positive_choices=None, negative_instances=False, fixed=['five_p']):\n",
    "    if negative_instances and len(positive_choices) <= 1:\n",
    "        raise ValueError\n",
    "    center = np.random.choice(mean_variants, 1)\n",
    "    total_count = int(np.random.normal(center, int(np.ceil(center * .2))))\n",
    "    if total_count < 1:\n",
    "        total_count *= -1\n",
    "    if total_count == 0:\n",
    "        total_count = np.random.choice([2, 3, 4, 5, 6], 1)\n",
    "    if control:\n",
    "        if negative_instances:\n",
    "            positive_count = int(np.ceil(np.random.random() * total_count))\n",
    "            control_count = total_count - positive_count\n",
    "        else:\n",
    "            control_count = total_count\n",
    "            positive_count = 0\n",
    "    else:\n",
    "        positive_counts = [int(np.ceil(np.random.random() / len(positive_choices) * total_count)) for i in positive_choices]\n",
    "        control_count = total_count - sum(positive_counts)\n",
    "\n",
    "    control_count = max(control_count, 0)\n",
    "    positive_variants = []\n",
    "    positive_instances = []\n",
    "\n",
    "    control_variants = [generate_variant() for i in range(control_count)]\n",
    "    if control:\n",
    "        while True:\n",
    "            y = False\n",
    "            for i in control_variants:\n",
    "                if check_variant(i, positive_choices, to_check=fixed):\n",
    "                    y = True\n",
    "                    break\n",
    "            if y:\n",
    "                control_variants = [generate_variant() for i in range(control_count)]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    if control:\n",
    "        if negative_instances:\n",
    "            positive_choice = int(np.random.choice(range(len(positive_choices)), 1))\n",
    "            for i in range(positive_count):\n",
    "                positive_variant = list(generate_variant())\n",
    "                if 'five_p' in fixed:\n",
    "                    positive_variant[0] = positive_choices[positive_choice][0]\n",
    "                if 'three_p' in fixed:\n",
    "                    positive_variant[1] = positive_choices[positive_choice][1]\n",
    "                if 'ref' in fixed:\n",
    "                    positive_variant[2] = positive_choices[positive_choice][2]\n",
    "                if 'alt' in fixed:\n",
    "                    positive_variant[3] = positive_choices[positive_choice][3]\n",
    "                positive_variants.append(positive_variant)\n",
    "                positive_instances.append(positive_choice + 1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        for index, i in enumerate(positive_choices):\n",
    "            for ii in range(positive_counts[index]):\n",
    "                positive_variant = list(generate_variant())\n",
    "                if 'five_p' in fixed:\n",
    "                    positive_variant[0] = i[0]\n",
    "                if 'three_p' in fixed:\n",
    "                    positive_variant[1] = i[1]\n",
    "                if 'ref' in fixed:\n",
    "                    positive_variant[2] = i[2]\n",
    "                if 'alt' in fixed:\n",
    "                    positive_variant[3] = i[3]\n",
    "                positive_variants.append(positive_variant)\n",
    "                positive_instances.append(index + 1)\n",
    "\n",
    "    return [control_variants + positive_variants, [0] * len(control_variants) + positive_instances]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will collect information about the individual mutations in a dictionary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "instances = {'sample_idx': [],\n",
    "                 'seq_5p': [],\n",
    "                 'seq_3p': [],\n",
    "                  'seq_ref': [],\n",
    "                  'seq_alt': [],\n",
    "                  'strand': [],\n",
    "                  'cds': [],\n",
    "                  'class': []}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#And we will also collect information about the samples the mutations belong to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "samples = {'classes': []}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Need to generate the motif which will define the positive class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "positive_choices = [generate_variant() for i in range(1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Let's make 1000 samples with approximately half of each class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(1000):\n",
    "    if np.random.sample() < .5:\n",
    "        variants = generate_sample(positive_choices=positive_choices)\n",
    "        samples['classes'] = samples['classes'] + [0]\n",
    "    else:\n",
    "        variants = generate_sample(control=False, positive_choices=positive_choices)\n",
    "        samples['classes'] = samples['classes'] + [1]\n",
    "    instances['sample_idx'] = instances['sample_idx'] + [idx] * len(variants[0])\n",
    "    instances['seq_5p'] = instances['seq_5p'] + [i[0] for i in variants[0]]\n",
    "    instances['seq_3p'] = instances['seq_3p'] + [i[1] for i in variants[0]]\n",
    "    instances['seq_ref'] = instances['seq_ref'] + [i[2] for i in variants[0]]\n",
    "    instances['seq_alt'] = instances['seq_alt'] + [i[3] for i in variants[0]]\n",
    "    instances['strand'] = instances['strand'] + [i[6] for i in variants[0]]\n",
    "    instances['cds'] = instances['cds'] + [0 for i in variants[0]]\n",
    "    instances['class'] = instances['class'] + variants[1]\n",
    "\n",
    "for i in instances:\n",
    "    instances[i] = np.array(instances[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples['classes'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0, 1]), array([478, 522]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(samples['classes'], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "97261"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances['sample_idx'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We made 1000 samples with 478 being of the negative class and 522 the positive class.  These samples are composed of 97261 mutations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Let's look at the distribution of mutations per sample.  You can alter the distribution to mirror the data you expect."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Mutations per Sample')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.unique(instances['sample_idx'], return_counts=True)[1], bins=50)\n",
    "plt.xlabel('Mutations per Sample')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'T' 'G' 'C' 'C' 'T']\n",
      " ['G' 'A' 'T' 'T' 'T' 'A']\n",
      " ['T' 'T' 'T' 'C' 'T' 'T']\n",
      " ['G' 'C' 'A' 'G' 'C' 'A']\n",
      " ['A' 'T' 'A' 'T' 'A' 'A']\n",
      " ['A' 'T' 'C' 'G' 'G' 'G']\n",
      " ['G' 'A' 'G' 'T' 'C' 'A']\n",
      " ['T' 'T' 'C' 'C' 'A' 'A']\n",
      " ['A' 'C' 'A' 'G' 'G' 'T']\n",
      " ['C' 'T' 'G' 'C' 'A' 'C']]\n"
     ]
    }
   ],
   "source": [
    "print(instances['seq_5p'][instances['class'] == 0][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']\n",
      " ['C' 'C' 'G' 'T' 'T' 'A']]\n"
     ]
    }
   ],
   "source": [
    "print(instances['seq_5p'][instances['class'] == 1][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The negative instances have random sequences 5' of the mutation as expected while the positive instances all have the same sequence.  We need to convert from nucleotide to a format the model can use."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "nucleotide_mapping = {'-': 0, 'N': 0, 'A': 1, 'T': 2, 'C': 3, 'G': 4}\n",
    "instances['seq_5p'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_5p']), axis=0)\n",
    "instances['seq_3p'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_3p']), axis=0)\n",
    "instances['seq_ref'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_ref']), axis=0)\n",
    "instances['seq_alt'] = np.stack(np.apply_along_axis(lambda x: np.array([nucleotide_mapping[i] for i in x]), -1, instances['seq_alt']), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The model will onehot this encoded data on the graph.  We need to stack the reverse of a variant with its forward counterpart to fully represent a variant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "variant_encoding = np.array([0, 2, 1, 4, 3])\n",
    "instances['seq_5p'] = np.stack([instances['seq_5p'], variant_encoding[instances['seq_3p'][:, ::-1]]], axis=2)\n",
    "instances['seq_3p'] = np.stack([instances['seq_3p'], variant_encoding[instances['seq_5p'][:, :, 0][:, ::-1]]], axis=2)\n",
    "t = instances['seq_ref'].copy()\n",
    "i = t != 0\n",
    "t[i] = variant_encoding[instances['seq_ref'][:, ::-1]][i[:, ::-1]]\n",
    "instances['seq_ref'] = np.stack([instances['seq_ref'], t], axis=2)\n",
    "t = instances['seq_alt'].copy()\n",
    "i = t != 0\n",
    "t[i] = variant_encoding[instances['seq_alt'][:, ::-1]][i[:, ::-1]]\n",
    "instances['seq_alt'] = np.stack([instances['seq_alt'], t], axis=2)\n",
    "del i, t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will onehot the strand ourselves, but it could have been done on graph."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "strand_emb_mat = np.concatenate([np.zeros(2)[np.newaxis, :], np.diag(np.ones(2))], axis=0)\n",
    "instances['strand_emb'] = strand_emb_mat[instances['strand']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We need to construct a ragged NumPy array using the sample indexes.  Using sample indexes allows for the possibility that the instances are not in order, for example instance of sample 1, instance of sample 2, instance of sample 1.  If you know that your data is in order then this operation could be done far more efficiently."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "indexes = [np.where(instances['sample_idx'] == idx) for idx in range(len(samples['classes']))]\n",
    "five_p = np.array([instances['seq_5p'][i] for i in indexes], dtype='object')\n",
    "three_p = np.array([instances['seq_3p'][i] for i in indexes], dtype='object')\n",
    "ref = np.array([instances['seq_ref'][i] for i in indexes], dtype='object')\n",
    "alt = np.array([instances['seq_alt'][i] for i in indexes], dtype='object')\n",
    "strand = np.array([instances['strand_emb'][i] for i in indexes], dtype='object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#In order to provide the graph ragged tensors we use loaders.  The loaders will automatically infer that ragged tensors need to be made from the fact that the arrays are dtype object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "five_p_loader = DatasetsUtils.Map.FromNumpy(five_p, tf.int32)\n",
    "three_p_loader = DatasetsUtils.Map.FromNumpy(three_p, tf.int32)\n",
    "ref_loader = DatasetsUtils.Map.FromNumpy(ref, tf.int32)\n",
    "alt_loader = DatasetsUtils.Map.FromNumpy(alt, tf.int32)\n",
    "strand_loader = DatasetsUtils.Map.FromNumpy(strand, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#A loader is not needed for data which will not be converted into a ragged tensor but can still be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "y_label = np.array(samples['classes'])[:, np.newaxis]\n",
    "y_strat = y_label\n",
    "y_label_loader = DatasetsUtils.Map.FromNumpy(y_label, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "idx_train, idx_test = next(StratifiedShuffleSplit(random_state=0, n_splits=1, test_size=200).split(y_strat, y_strat))\n",
    "idx_train, idx_valid = [idx_train[idx] for idx in list(StratifiedShuffleSplit(n_splits=1, test_size=300, random_state=0).split(np.zeros_like(y_strat)[idx_train], y_strat[idx_train]))[0]]\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((idx_train, y_strat[idx_train]))\n",
    "ds_train = ds_train.apply(DatasetsUtils.Apply.StratifiedMinibatch(batch_size=100, ds_size=len(idx_train)))\n",
    "ds_train = ds_train.map(lambda x: ((five_p_loader(x),\n",
    "                                    three_p_loader(x),\n",
    "                                    ref_loader(x),\n",
    "                                    alt_loader(x),\n",
    "                                    strand_loader(x)),\n",
    "                                    y_label_loader(x)\n",
    "                                   ))\n",
    "\n",
    "\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(((five_p_loader(idx_valid),\n",
    "                                                three_p_loader(idx_valid),\n",
    "                                                ref_loader(idx_valid),\n",
    "                                                alt_loader(idx_valid),\n",
    "                                                strand_loader(idx_valid),\n",
    "                                                ),\n",
    "                                               tf.gather(y_label, idx_valid),\n",
    "                                               ))\n",
    "ds_valid = ds_valid.batch(len(idx_valid), drop_remainder=False)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(((five_p_loader(idx_test),\n",
    "                                                three_p_loader(idx_test),\n",
    "                                                ref_loader(idx_test),\n",
    "                                                alt_loader(idx_test),\n",
    "                                                strand_loader(idx_test),\n",
    "                                                ),\n",
    "                                               tf.gather(y_label, idx_test),\n",
    "                                               ))\n",
    "ds_test = ds_test.batch(len(idx_test), drop_remainder=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We need to build our sequence encoder.  The sequences are 6 nucleotides long, have an embedding dimension of 4, and have 2 strands.  We will use 16 kernels for the 5' and 3' sequences, and 8 kernels for the ref and alt sequences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "tile_encoder = InstanceModels.VariantSequence(6, 4, 2, [16, 16, 8, 8])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will build our MIL model with the default parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "mil = RaggedModels.MIL(instance_encoders=[tile_encoder.model])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 16:58:19.535310: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 206ms/step - loss: 1.5316 - accuracy: 0.4784 - binary_crossentropy: 0.9080 - val_loss: 1.2865 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6897\n",
      "Epoch 2/10000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.2582 - accuracy: 0.4772 - binary_crossentropy: 0.6815 - val_loss: 1.2238 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6702\n",
      "Epoch 3/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2030 - accuracy: 0.4784 - binary_crossentropy: 0.6657 - val_loss: 1.1695 - val_accuracy: 0.4767 - val_binary_crossentropy: 0.6508\n",
      "Epoch 4/10000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 1.1563 - accuracy: 0.4784 - binary_crossentropy: 0.6512 - val_loss: 1.1239 - val_accuracy: 0.4833 - val_binary_crossentropy: 0.6344\n",
      "Epoch 5/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.1044 - accuracy: 0.5360 - binary_crossentropy: 0.6265 - val_loss: 1.0663 - val_accuracy: 0.5333 - val_binary_crossentropy: 0.6017\n",
      "Epoch 6/10000\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 1.0505 - accuracy: 0.5829 - binary_crossentropy: 0.5954 - val_loss: 1.0026 - val_accuracy: 0.6800 - val_binary_crossentropy: 0.5580\n",
      "Epoch 7/10000\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.9830 - accuracy: 0.6727 - binary_crossentropy: 0.5449 - val_loss: 0.9141 - val_accuracy: 0.7533 - val_binary_crossentropy: 0.4826\n",
      "Epoch 8/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9077 - accuracy: 0.7566 - binary_crossentropy: 0.4792 - val_loss: 0.8199 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3941\n",
      "Epoch 9/10000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8131 - accuracy: 0.8293 - binary_crossentropy: 0.3901 - val_loss: 0.7336 - val_accuracy: 0.8967 - val_binary_crossentropy: 0.3149\n",
      "Epoch 10/10000\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.7437 - accuracy: 0.8561 - binary_crossentropy: 0.3305 - val_loss: 0.6527 - val_accuracy: 0.9033 - val_binary_crossentropy: 0.2478\n",
      "Epoch 11/10000\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.6790 - accuracy: 0.8777 - binary_crossentropy: 0.2829 - val_loss: 0.5962 - val_accuracy: 0.9433 - val_binary_crossentropy: 0.2090\n",
      "Epoch 12/10000\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6136 - accuracy: 0.8942 - binary_crossentropy: 0.2340 - val_loss: 0.5554 - val_accuracy: 0.9633 - val_binary_crossentropy: 0.1835\n",
      "Epoch 13/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.5654 - accuracy: 0.9329 - binary_crossentropy: 0.2014 - val_loss: 0.4936 - val_accuracy: 0.9633 - val_binary_crossentropy: 0.1375\n",
      "Epoch 14/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.5157 - accuracy: 0.9472 - binary_crossentropy: 0.1652 - val_loss: 0.4571 - val_accuracy: 0.9800 - val_binary_crossentropy: 0.1121\n",
      "Epoch 15/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4775 - accuracy: 0.9579 - binary_crossentropy: 0.1383 - val_loss: 0.4266 - val_accuracy: 0.9833 - val_binary_crossentropy: 0.0943\n",
      "Epoch 16/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4426 - accuracy: 0.9676 - binary_crossentropy: 0.1158 - val_loss: 0.4038 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0834\n",
      "Epoch 17/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.4236 - accuracy: 0.9640 - binary_crossentropy: 0.1097 - val_loss: 0.3896 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0790\n",
      "Epoch 18/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3966 - accuracy: 0.9736 - binary_crossentropy: 0.0929 - val_loss: 0.3730 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0729\n",
      "Epoch 19/10000\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3831 - accuracy: 0.9724 - binary_crossentropy: 0.0906 - val_loss: 0.3466 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0607\n",
      "Epoch 20/10000\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3701 - accuracy: 0.9760 - binary_crossentropy: 0.0873 - val_loss: 0.3327 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0542\n",
      "Epoch 21/10000\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3436 - accuracy: 0.9796 - binary_crossentropy: 0.0675 - val_loss: 0.3255 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0535\n",
      "Epoch 22/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.3356 - accuracy: 0.9784 - binary_crossentropy: 0.0692 - val_loss: 0.3150 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0511\n",
      "Epoch 23/10000\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.3208 - accuracy: 0.9868 - binary_crossentropy: 0.0616 - val_loss: 0.2997 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0455\n",
      "Epoch 24/10000\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.3107 - accuracy: 0.9856 - binary_crossentropy: 0.0606 - val_loss: 0.2886 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0433\n",
      "Epoch 25/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3001 - accuracy: 0.9808 - binary_crossentropy: 0.0582 - val_loss: 0.2910 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0489\n",
      "Epoch 26/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2896 - accuracy: 0.9856 - binary_crossentropy: 0.0550 - val_loss: 0.2705 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0393\n",
      "Epoch 27/10000\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2797 - accuracy: 0.9904 - binary_crossentropy: 0.0519 - val_loss: 0.2637 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0384\n",
      "Epoch 28/10000\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2646 - accuracy: 0.9892 - binary_crossentropy: 0.0446 - val_loss: 0.2538 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0362\n",
      "Epoch 29/10000\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2648 - accuracy: 0.9904 - binary_crossentropy: 0.0496 - val_loss: 0.2450 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0350\n",
      "Epoch 30/10000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2481 - accuracy: 0.9904 - binary_crossentropy: 0.0405 - val_loss: 0.2402 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0349\n",
      "Epoch 31/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2419 - accuracy: 0.9904 - binary_crossentropy: 0.0411 - val_loss: 0.2347 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0346\n",
      "Epoch 32/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.2331 - accuracy: 0.9904 - binary_crossentropy: 0.0389 - val_loss: 0.2266 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0324\n",
      "Epoch 33/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2292 - accuracy: 0.9904 - binary_crossentropy: 0.0392 - val_loss: 0.2189 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0313\n",
      "Epoch 34/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.2195 - accuracy: 0.9916 - binary_crossentropy: 0.0356 - val_loss: 0.2105 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0299\n",
      "Epoch 35/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.2141 - accuracy: 0.9904 - binary_crossentropy: 0.0358 - val_loss: 0.2033 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0283\n",
      "Epoch 36/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2041 - accuracy: 0.9940 - binary_crossentropy: 0.0307 - val_loss: 0.1989 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0280\n",
      "Epoch 37/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2017 - accuracy: 0.9904 - binary_crossentropy: 0.0342 - val_loss: 0.1918 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0272\n",
      "Epoch 38/10000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.1904 - accuracy: 0.9976 - binary_crossentropy: 0.0274 - val_loss: 0.1866 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0260\n",
      "Epoch 39/10000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.1856 - accuracy: 0.9940 - binary_crossentropy: 0.0285 - val_loss: 0.1842 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0269\n",
      "Epoch 40/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1815 - accuracy: 0.9940 - binary_crossentropy: 0.0290 - val_loss: 0.1795 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0269\n",
      "Epoch 41/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1727 - accuracy: 0.9964 - binary_crossentropy: 0.0234 - val_loss: 0.1709 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0256\n",
      "Epoch 42/10000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1714 - accuracy: 0.9928 - binary_crossentropy: 0.0261 - val_loss: 0.1664 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0261\n",
      "Epoch 43/10000\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1655 - accuracy: 0.9952 - binary_crossentropy: 0.0247 - val_loss: 0.1659 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.0240\n",
      "Epoch 44/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.1617 - accuracy: 0.9940 - binary_crossentropy: 0.0242 - val_loss: 0.1582 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0226\n",
      "Epoch 45/10000\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1542 - accuracy: 0.9964 - binary_crossentropy: 0.0213 - val_loss: 0.1548 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0226\n",
      "Epoch 46/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.1493 - accuracy: 0.9988 - binary_crossentropy: 0.0206 - val_loss: 0.1504 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0220\n",
      "Epoch 47/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1434 - accuracy: 0.9988 - binary_crossentropy: 0.0186 - val_loss: 0.1460 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0221\n",
      "Epoch 48/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1428 - accuracy: 1.0000 - binary_crossentropy: 0.0199 - val_loss: 0.1421 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0229\n",
      "Epoch 49/10000\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.1372 - accuracy: 0.9988 - binary_crossentropy: 0.0193 - val_loss: 0.1389 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0219\n",
      "Epoch 50/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1310 - accuracy: 0.9988 - binary_crossentropy: 0.0165 - val_loss: 0.1359 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0211\n",
      "Epoch 51/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1293 - accuracy: 1.0000 - binary_crossentropy: 0.0169 - val_loss: 0.1318 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0209\n",
      "Epoch 52/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1273 - accuracy: 0.9988 - binary_crossentropy: 0.0181 - val_loss: 0.1314 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0214\n",
      "Epoch 53/10000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1243 - accuracy: 0.9976 - binary_crossentropy: 0.0179 - val_loss: 0.1248 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 54/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1190 - accuracy: 1.0000 - binary_crossentropy: 0.0138 - val_loss: 0.1239 - val_accuracy: 0.9900 - val_binary_crossentropy: 0.0238\n",
      "Epoch 55/10000\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1173 - accuracy: 0.9976 - binary_crossentropy: 0.0146 - val_loss: 0.1199 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0196\n",
      "Epoch 56/10000\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.1130 - accuracy: 0.9976 - binary_crossentropy: 0.0159 - val_loss: 0.1232 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0225\n",
      "Epoch 57/10000\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1102 - accuracy: 1.0000 - binary_crossentropy: 0.0139 - val_loss: 0.1154 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0195\n",
      "Epoch 58/10000\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1054 - accuracy: 1.0000 - binary_crossentropy: 0.0118 - val_loss: 0.1122 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0201\n",
      "Epoch 59/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1040 - accuracy: 1.0000 - binary_crossentropy: 0.0133 - val_loss: 0.1099 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0204\n",
      "Epoch 60/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1002 - accuracy: 1.0000 - binary_crossentropy: 0.0122 - val_loss: 0.1076 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0199\n",
      "Epoch 61/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0983 - accuracy: 1.0000 - binary_crossentropy: 0.0120 - val_loss: 0.1053 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0197\n",
      "Epoch 62/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0948 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 0.1039 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0199\n",
      "Epoch 63/10000\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0930 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 0.1008 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 64/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0901 - accuracy: 1.0000 - binary_crossentropy: 0.0103 - val_loss: 0.0986 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 65/10000\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0882 - accuracy: 1.0000 - binary_crossentropy: 0.0106 - val_loss: 0.0969 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0193\n",
      "Epoch 66/10000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.0860 - accuracy: 1.0000 - binary_crossentropy: 0.0101 - val_loss: 0.0953 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0195\n",
      "Epoch 67/10000\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0832 - accuracy: 1.0000 - binary_crossentropy: 0.0095 - val_loss: 0.0934 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0192\n",
      "Epoch 68/10000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0824 - accuracy: 1.0000 - binary_crossentropy: 0.0098 - val_loss: 0.0922 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0194\n",
      "Epoch 69/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0793 - accuracy: 1.0000 - binary_crossentropy: 0.0092 - val_loss: 0.0902 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0194\n",
      "Epoch 70/10000\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.0780 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 0.0893 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 71/10000\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0761 - accuracy: 1.0000 - binary_crossentropy: 0.0089 - val_loss: 0.0863 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0196\n",
      "Epoch 72/10000\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0733 - accuracy: 1.0000 - binary_crossentropy: 0.0082 - val_loss: 0.0852 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 73/10000\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0713 - accuracy: 1.0000 - binary_crossentropy: 0.0079 - val_loss: 0.0829 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0193\n",
      "Epoch 74/10000\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0712 - accuracy: 1.0000 - binary_crossentropy: 0.0088 - val_loss: 0.0843 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0207\n",
      "Epoch 75/10000\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.0692 - accuracy: 1.0000 - binary_crossentropy: 0.0079 - val_loss: 0.0803 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 76/10000\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0669 - accuracy: 1.0000 - binary_crossentropy: 0.0072 - val_loss: 0.0788 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0195\n",
      "Epoch 77/10000\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0656 - accuracy: 1.0000 - binary_crossentropy: 0.0077 - val_loss: 0.0786 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 78/10000\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0640 - accuracy: 1.0000 - binary_crossentropy: 0.0075 - val_loss: 0.0773 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0201\n",
      "Epoch 79/10000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.0624 - accuracy: 1.0000 - binary_crossentropy: 0.0071 - val_loss: 0.0753 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0196\n",
      "Epoch 80/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0608 - accuracy: 1.0000 - binary_crossentropy: 0.0068 - val_loss: 0.0737 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 81/10000\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0597 - accuracy: 1.0000 - binary_crossentropy: 0.0065 - val_loss: 0.0728 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0200\n",
      "Epoch 82/10000\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0583 - accuracy: 1.0000 - binary_crossentropy: 0.0066 - val_loss: 0.0709 - val_accuracy: 0.9967 - val_binary_crossentropy: 0.0198\n",
      "Epoch 83/10000\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0574 - accuracy: 1.0000 - binary_crossentropy: 0.0064 - val_loss: 0.0716 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0202\n",
      "Epoch 84/10000\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0564 - accuracy: 1.0000 - binary_crossentropy: 0.0069 - val_loss: 0.0710 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0201\n",
      "Epoch 85/10000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.0555 - accuracy: 1.0000 - binary_crossentropy: 0.0062 - val_loss: 0.0691 - val_accuracy: 0.9933 - val_binary_crossentropy: 0.0199\n",
      "Epoch 86/10000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0544 - accuracy: 1.0000 - binary_crossentropy: 0.0070 - val_loss: 0.0680 - val_accuracy: 0.9900 - val_binary_crossentropy: 0.0216\n",
      "Epoch 87/10000\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0571 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 0.0819 - val_accuracy: 0.9833 - val_binary_crossentropy: 0.0387\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1144 - accuracy: 0.9900 - binary_crossentropy: 0.0351\n"
     ]
    }
   ],
   "source": [
    "losses = [tf.keras.losses.BinaryCrossentropy(from_logits=True)]\n",
    "mil.model.compile(loss=losses,\n",
    "                  metrics=['accuracy', tf.keras.metrics.BinaryCrossentropy(from_logits=True)],\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                ))\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', min_delta=0.00001, patience=20, mode='min', restore_best_weights=True)]\n",
    "history = mil.model.fit(ds_train, steps_per_epoch=10, validation_data=ds_valid, epochs=10000, callbacks=callbacks)\n",
    "evaluation = mil.model.evaluate(ds_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Check the performance on test data, this model achieved 99% accuracy on this task."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11439504474401474, 0.9900000095367432, 0.035059455782175064]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#To get the attention we call a separate model which was built by default."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "attention = mil.attention_model.predict(ds_test).to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#The attention is a list per sample."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Attention')"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.concatenate(attention), bins=100)\n",
    "plt.xlabel('Attention')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#As we can see most instances received low attention while some received higher attention."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}